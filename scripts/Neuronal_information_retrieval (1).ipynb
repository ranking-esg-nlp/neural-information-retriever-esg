{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjViSiQENW_Z"
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from nltk import sent_tokenize\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "3nSAttQPTbw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PROCESO NEURONAL INFORMATION RETRIEVAL"
      ],
      "metadata": {
        "id": "XDgQQwF5TcRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Corpus_esg:\n",
        "\n",
        "    def __init__(self, empresa, año):\n",
        "        self.empresa = empresa\n",
        "        self.año = año\n",
        "        self.passages=[]\n",
        "    def get_path(self):\n",
        "        \"\"\"me da el path correspondiente de ese año esa empresa\"\"\"\n",
        "        path_origen='/content/drive/MyDrive/DATO-ingles/'+self.empresa+'/'+str(self.año)+'/'\n",
        " \n",
        "        return path_origen\n",
        "\n",
        "    def get_archivos(self,formato):\n",
        "          '''\n",
        "          Coge los archivos de cada empresa y año que sean de un formato determinado\n",
        "          Args:\n",
        "                    formato (str): se cogeran los archivos de este formato , por defecto txt\n",
        "\n",
        "          Return : una lsita con los archivos del formato indicado\n",
        "          '''\n",
        "        path_origen=self.get_path()\n",
        "  \n",
        "        contenido = os.listdir(path_origen)\n",
        "        for archivo in contenido:\n",
        "          tipo=archivo[-3:]\n",
        "          if tipo !=formato:\n",
        "            contenido.remove(archivo)\n",
        "        \n",
        "        return contenido\n",
        "\n",
        "    def almacen_texto(self,formato='txt'):\n",
        "      '''\n",
        "      Divide el contenido de los archivos en parrafos\n",
        "      Args:\n",
        "              \n",
        "                formato (str): se cogeran los archivos de este formato , por defecto txt\n",
        "\n",
        "      Return : una lista con los parrafos de todos los archivos del formato indicado \n",
        "      '''\n",
        "      contenido=self.get_archivos(formato=formato)\n",
        "      passages = []\n",
        "      for archivo in contenido:\n",
        "        nombre=archivo[:-4]\n",
        "        print(nombre)\n",
        "        path=self.get_path()+nombre+'.'+formato\n",
        "        document = open(path, 'r', encoding=\"utf-8\")\n",
        "        document=document.read() \n",
        "        paragraphs = []\n",
        "        for paragraph in document.replace(\"\\r\\n\", \"\\n\").split(\"\\n\\n\"):\n",
        "              if len(paragraph.strip()) > 0:\n",
        "                  paragraphs.append(sent_tokenize(paragraph.strip()))\n",
        "\n",
        "        window_size = 20\n",
        "        \n",
        "        for paragraph in paragraphs:\n",
        "              for start_idx in range(0, len(paragraph), window_size):\n",
        "                  end_idx = min(start_idx+window_size, len(paragraph))\n",
        "                  passages.append(\" \".join(paragraph[start_idx:end_idx]))\n",
        "      return passages\n",
        "    def cargar_almacen_texto(self):\n",
        "      '''\n",
        "      Guardar los parrafos como argumento de la clase\n",
        "      Return : una lista con los parrafos de todos los archivos del formato indicado \n",
        "      '''\n",
        "      passages=self.almacen_texto()\n",
        "      self.passages=passages\n",
        "\n",
        "      return passages\n",
        "\n",
        "    def descargar_almacen_texto(self):\n",
        "      '''\n",
        "      Guardar los parrafos en drive en formato csv\n",
        "\n",
        "      \n",
        "      '''\n",
        "      dicc = {'passages': self.passages} \n",
        "      df = pd.DataFrame(dicc)\n",
        "      nombre='corpus.csv'\n",
        "      path=self.get_path()+nombre\n",
        "      df.to_csv(path)\n",
        "    def cargar_almacen_texto_drive(self):\n",
        "      '''\n",
        "      carga los parrafos que estan guardados en el drive\n",
        "\n",
        "      Return : una lista con los parrafos \n",
        "      '''\n",
        "      path=self.get_path()+'corpus.csv'\n",
        "      datos=pd.read_csv(path)\n",
        "      passages=datos['passages'].tolist()\n",
        "      return passages"
      ],
      "metadata": {
        "id": "5FOED_WbTj8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Retriever_esg:\n",
        "      def __init__(self, corpus, pregunta):\n",
        "        self.corpus = corpus\n",
        "        self.pregunta = pregunta\n",
        "        self.corpus_retriever=[]\n",
        "      def passage_embedding(self):\n",
        "        '''\n",
        "        Realiza el embedding de los parrafos con el modelo que hemos elegido\n",
        "\n",
        "        '''\n",
        "        passage_encoder = SentenceTransformer('facebook-dpr-ctx_encoder-single-nq-base')\n",
        "\n",
        "        passage_embeddings = passage_encoder.encode(self.corpus)\n",
        "        return passage_embeddings\n",
        "\n",
        "      def query_embedding(self):\n",
        "        '''\n",
        "        Realiza el embedding de la query con el modelo que hemos elegido\n",
        "\n",
        "        '''\n",
        "        query_encoder = SentenceTransformer('facebook-dpr-question_encoder-single-nq-base')\n",
        "        query_embedding = query_encoder.encode(self.pregunta)\n",
        "        return query_embedding\n",
        "\n",
        "      def retriever(self):\n",
        "        '''\n",
        "        Realiza el document retriever: para ello realiza el embedding de los parrafos y la query, para \n",
        "        codificar la query y los passages en un espacio dimensinal y luego le aplica el producto escalar como\n",
        "        funcion de similitud para comparar cada parrafo y la query. \n",
        "\n",
        "        Una vez obtenida la similitud entre la query y cada parrafo se eligen como posibles parrafos aquellos que tiene \n",
        "        un 20% o menos de diferencia con el parrafo con mas similitud.\n",
        "\n",
        "        Return : lista con aqueelos parrafos con una cierta similitud con la query. y que por tanto es posible\n",
        "        que la respuesta este en uno de ellos\n",
        "        '''\n",
        "        document_retriever=[]\n",
        "        num_passages=len(self.corpus)\n",
        "        passage_embeddings=self.passage_embedding()\n",
        "        query_embedding=self.query_embedding()\n",
        "        scores = util.dot_score(query_embedding, passage_embeddings)\n",
        "        maxima_probabilidad=max(list(scores.numpy()[0]))\n",
        "        minima_probabilidad=maxima_probabilidad-20\n",
        "        print(maxima_probabilidad,minima_probabilidad)\n",
        "        for i in range(0,num_passages):\n",
        "          score=list(scores.numpy()[0])[i]\n",
        "          if score>minima_probabilidad:\n",
        "            document_retriever.append(passages[i])\n",
        "        return document_retriever\n",
        "\n",
        "      def cargar_corpus_retirever(self):\n",
        "        \n",
        "        corpus_r=self.retriever()\n",
        "        self.corpus_retirever=corpus_r\n",
        "        return corpus_r\n",
        "\n",
        "      def generar_contexto(self):\n",
        "        '''\n",
        "        Esta funcion se encarga de generar el contexto donde puede estar la respuesta, y para ello \n",
        "        junta todos los parrafos que el document retriever considera posibles de que este la pregunta\n",
        "\n",
        "        Return : el texto de juntar todos los parrafos\n",
        "        '''\n",
        "        contexto=''\n",
        "        corpus_r=self.corpus_retriever\n",
        "        for passage in corpus_r:\n",
        "          contexto +=passage\n",
        "          contexto +='\\n'\n",
        "        return contexto"
      ],
      "metadata": {
        "id": "yFY3XeV0WXqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Reader_esg:\n",
        "  def __init__(self, contexto, pregunta):\n",
        "        self.contexto = contexto\n",
        "        self.pregunta = pregunta\n",
        "        \n",
        "  def document_reader(self):\n",
        "    '''\n",
        "    Realiza el document reader: para ello utiliza el modelo que hemos estudiado: roberta-bas-squad2\n",
        "\n",
        "\n",
        "    Return : devuelva la respuesta dada por el modelo y el porcentaje con el que cree que lo ha \n",
        "    hecho bien\n",
        "    '''\n",
        "    model_name = \"deepset/roberta-base-squad2\"\n",
        "    nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
        "    QA_input = {\n",
        "        'question': self.pregunta,\n",
        "        'context': self.contexto\n",
        "          }\n",
        "    res = nlp(QA_input)\n",
        "    answer = res['answer']\n",
        "    score=res['score']\n",
        "    return [answer,score,res]"
      ],
      "metadata": {
        "id": "etZuj5wJYKs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FUNCIONES AUXILIARES"
      ],
      "metadata": {
        "id": "SGYWFDieY0aV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def años_con_datos(empresa):\n",
        "  '''\n",
        "  busca para cada empresa de que años tiene disponible informacion\n",
        "  Args:\n",
        "            empresa (str): empresa de la que se busca \n",
        "\n",
        "\n",
        "  Return : una lista con los años donde la empresa tiene informacion\n",
        "  '''\n",
        "  path_origen='/content/drive/MyDrive/DATO-ingles/'+empresa+'/'\n",
        "  contenido = os.listdir(path_origen)\n",
        "  #me devuelve una lsita con los años\n",
        "  return contenido"
      ],
      "metadata": {
        "id": "e_Kx5rm7Y2Hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crear_corpus(empresa, año):\n",
        "      '''\n",
        "      Dada un año y una empresa crea el corpus \n",
        "      Args:\n",
        "            empresa str: empresa a estudiar\n",
        "            año str: año a estudiar\n",
        "\n",
        "        Returns:\n",
        "            corpus\n",
        "      '''\n",
        "  # 1º paso:crear la clase\n",
        "  cor=Corpus_esg(empresa, año)\n",
        "  # 2º paso:crear corpus y guardar passages\n",
        "  print('crear corpus')\n",
        "  corpus=cor.cargar_almacen_texto()\n",
        "  # 3º paso: guardar en drive para tenerlo descargado\n",
        "  cor.descargar_almacen_texto()\n",
        "  \n",
        "\n",
        "  return corpus"
      ],
      "metadata": {
        "id": "tm8v6WBeZk3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crear_retriver(corpus,pregunta):\n",
        "  # 1º paso:crear la clase\n",
        "  ret=Retriever_esg(corpus,pregunta)\n",
        "  # 2º paso:crear retriver y guardar en la clase\n",
        "  corpus_retirever=ret.cargar_corpus_retirever()\n",
        "  return corpus_retriever"
      ],
      "metadata": {
        "id": "3kzF0OcYan0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crear_reader(corpus,pregunta):\n",
        "  # 1º paso:crear la clase\n",
        "  reader=Reader_esg(corpus,pregunta)\n",
        "  # 2º paso:crear reader y sacar respuesta\n",
        "  respuesta=ret.document_reader()\n",
        "  return respuesta"
      ],
      "metadata": {
        "id": "uryOJe7Nbikx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imprimir_respuestas(respuesta, variable,question, empresa, año,dimension):\n",
        "\n",
        "  '''\n",
        "  Guarda las respuesta dadas por el document reader en drive.\n",
        "\n",
        "  Args:\n",
        "            respuesta (str): respuesta dada por el Reader\n",
        "            question (str): query con la que se define la variable \n",
        "            variable (str): nombre de la variable que buscamos\n",
        "            empresa(str): empresa de la que estamos buscando\n",
        "            año(str): año donde estamos buscando\n",
        "            dimension(str): dimension a la que pertenece la variable (e,g,s)\n",
        "\n",
        "  \n",
        "  '''\n",
        "\n",
        "  nombre='/content/drive/MyDrive/DATO-ingles/resultados_busquedas/'+empresa+'_'+año+'_resultados_'+dimension+'.txt'\n",
        "  answer=respuesta[0]\n",
        "  score=respuesta[1]\n",
        "  res=respuesta[2]\n",
        "  f = open(nombre, 'a')\n",
        "  \n",
        "  f.write('\\n')\n",
        "  f.write('---------------------------------------------')\n",
        "  f.write('\\n')\n",
        "  f.write('la variable que estamos buscando es: '+ variable)\n",
        "  f.write('\\n')\n",
        "  f.write('la query con la que buscamos : ' + question)\n",
        "  f.write('\\n')\n",
        "  f.write('la respuesta que da el modelo es : ' +str(answer) )\n",
        "  f.write('\\n')\n",
        "  f.write('la respuesta tiene una fiabilidad de: ' + str(score))\n",
        "  f.write('\\n')\n",
        "  f.write('la respuesta completa es: ' + str(res))\n",
        "  f.write('---------------------------------------------')\n",
        "  f.write('\\n')\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "oy0A1-a0c5_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def proceso_pipeline(corpus,diccionario_preguntas,dimension, empresa,año):\n",
        "  '''\n",
        "  funcion que realiza todo el proceso NIR\n",
        "\n",
        "  1º paso: hacer el document_retriever\n",
        "  2º paso: hacer el document_Reader, calcula la respuesta de la variable y guarda los resultados en drive\n",
        "\n",
        "  Args:\n",
        "            corpus (str): texto que contiene la informacion de la empresa para ese año\n",
        "            diccionario_preguntas (dic): diccionario con las variables y sus respectivas querys\n",
        "            empresa(str): empresa de la que estamos buscando\n",
        "            año(str): año donde estamos buscando\n",
        "            dimension(str): dimension a la que pertenece el diccionario (e,g,s)\n",
        "\n",
        "\n",
        "  '''\n",
        "  \n",
        "  for variable in diccionario_preguntas:\n",
        "    pregunta=diccionario_preguntas[variable]\n",
        "    corpus_retriever=crear_retriver(corpus,pregunta)\n",
        "    respuesta=crear_reade(corpus_retriever,pregunta)\n",
        "    imprimir_respuestas(respuesta,variable=variable,question=pregunta, empresa=empresa, año=año, dimension=dimension)"
      ],
      "metadata": {
        "id": "GhKdfeBfcLRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PROCESO DADO UNA EMPRESA"
      ],
      "metadata": {
        "id": "3pbfQa3HZCYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos la empresa a estudiar"
      ],
      "metadata": {
        "id": "PeLWi2WlZEWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "empresa='acciona'"
      ],
      "metadata": {
        "id": "qZXj1aKmZGg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#diccionario con los indicadores que buscamos y sus preguntas\n",
        "preguntas_e={'recognized_env_standard':'Is the environmental management system certified through an international standard such as ISO 14001, JIS Q 14001 or EMAS?',\n",
        "                 'external_audit':'Is the environmental management system verified by a specialized external audit?',\n",
        "                 'total_emissions_co2':'total amount of co2 emissions in tons',\n",
        "                 '2030_commitment':'has a commitment on the 2030 GHG according to the EU policy to reduce greenhouse gases?',\n",
        "               'energy_use':'Do you have a policy to manage the use of energy to achieve savings by using energy efficiently or renewable energy?',\n",
        "                'manage_waste':'Do you have a waste management policy to avoid or reduce waste through a more efficient use of resources?',\n",
        "                'biodiversity':'Commitment to conserve biodiversity and ecosystems',\n",
        "                'climate_strategy':'has a Report on vulnerability to climate change to identify opportunities and risks associated with climate change through the recommendations of the Task Force on Climate Related Financial Disclosures TCFD?',\n",
        "                'water_use':'Do you have a policy to manage use of water (efforts to manage water-related risks and opportunities)?',\n",
        "                  'clean_tech':'implement the use of electric or hybrid vehicles (gas-electric)?', \n",
        "                 'green_buildings':'improvement of the environmental performance of your real estate assets with owned buildings that have the green certificate?',\n",
        "'renewable_energy':'Has a policy to generate renewable energy and/or allow renewable energy development through grid expansion and \"green energy\" offerings?',\n",
        " 'waste_use':'total amount of waste used or disposed in tons',\n",
        "             'waste_recycled':'total amount of recycled waste in tons',\n",
        "             'water_used':'total amount of water discharged or used in m3',\n",
        "             'water_recycled':'total amount of water that is of recycled origin or that is recycled in m3',\n",
        "             'w_renewable_energy':'number of watts of renewable energy',\n",
        "             'circular_economy':'circular economy policy that involver reusing, repairing, renewing and recycling existing materials and products for as long as possible'}"
      ],
      "metadata": {
        "id": "v701JcKWeCGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "años=años_con_datos(empresa)\n",
        "for año in años:\n",
        "      #para cada año se crea el corpus, este es igual para todas las preguntas\n",
        "      corpus=crear_corpus(empresa, año)\n",
        "      proceso_pipeline(corpus,diccionario_preguntas=preguntas_e,dimension='e',empresa,año) "
      ],
      "metadata": {
        "id": "QguZe_KEZH8Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}